{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook aims to show a minimal reproducing example to use our trained models for inference.\n",
    "Here, we only evaluate our model from the *first* run, while the results reported in the main paper are averaged across all executed runs, e.g., 10 runs for `ogbg-molhiv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n",
    "from torch_geometric.datasets import ZINC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.transforms import RemoveIsolatedNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypercomplex.undirectional.models import PHMSkipConnectAdd as UPH_SC_ADD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OGB framework\n",
    "from train_hiv import test_validate as test_validate_hiv\n",
    "from train_pcba import test_validate as test_validate_pcba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customized\n",
    "from train_zinc import test_validate as test_validate_zinc\n",
    "from train_zinc import Evaluator as zinc_Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_infos(model):\n",
    "    mp_layers = [mp * model.phm_dim for mp in model.mp_layers]\n",
    "    dn_layers = [mp * model.phm_dim for mp in model.downstream_layers]\n",
    "    print(f\"Model consists of {model.get_number_of_params_()} trainable parameters.\")\n",
    "    print(f\"PHC-dim: {model.phm_dim}\")\n",
    "    print(f\"Message passing layers: {mp_layers}.\")\n",
    "    print(f\"Downstream layers: {dn_layers}.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "PRE_TRAFO = False # for dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ogbg-molhiv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['params.json',\n",
       " 'run_1',\n",
       " 'run_10',\n",
       " 'run_2',\n",
       " 'run_3',\n",
       " 'run_4',\n",
       " 'run_5',\n",
       " 'run_6',\n",
       " 'run_7',\n",
       " 'run_8',\n",
       " 'run_9',\n",
       " 'run.log']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"hiv/experiment1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hiv/experiment1/params.json\", \"r\") as f:\n",
    "    run_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device': 0,\n",
       " 'nworkers': 0,\n",
       " 'pin_memory': 'True',\n",
       " 'batch_size': 128,\n",
       " 'save_dir': 'hiv/experiment1',\n",
       " 'n_runs': 10,\n",
       " 'seed': 0,\n",
       " 'pooling': 'softattention',\n",
       " 'type': 'undirectional-phm-sc-add',\n",
       " 'phm_dim': 4,\n",
       " 'learn_phm': 'True',\n",
       " 'unique_phm': 'False',\n",
       " 'init': 'phm',\n",
       " 'input_embed_dim': 200,\n",
       " 'embed_combine': 'sum',\n",
       " 'full_encoder': 'True',\n",
       " 'mp_units': '200,200',\n",
       " 'mp_norm': 'naive-batch-norm',\n",
       " 'mlp_mp': 'True',\n",
       " 'dropout_mpnn': '0.3,0.3',\n",
       " 'same_dropout': 'False',\n",
       " 'bias': 'True',\n",
       " 'd_units': '128,32',\n",
       " 'd_bn': 'naive-batch-norm',\n",
       " 'dropout_dn': '0.3,0.1',\n",
       " 'activation': 'relu',\n",
       " 'aggr_msg': 'softmax',\n",
       " 'aggr_node': 'softmax',\n",
       " 'msg_scale': 'False',\n",
       " 'real_trafo': 'linear',\n",
       " 'epochs': 50,\n",
       " 'lr': 0.001,\n",
       " 'patience': 5,\n",
       " 'factor': 0.75,\n",
       " 'weightdecay': 0.1,\n",
       " 'regularization': 2,\n",
       " 'grad_clipping': 2.0,\n",
       " 'log_weights': 'False',\n",
       " 'msg_encoder': 'identity'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset and loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dname=\"ogbg-molhiv\"\n",
    "dataset = PygGraphPropPredDataset(name=dname, root=\"dataset\", transform=None)\n",
    "evaluator = Evaluator(name=dname)\n",
    "split_idx = dataset.get_idx_split()\n",
    "transform = RemoveIsolatedNodes()  # will be applied in the test_validate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test split sample size:  4113\n"
     ]
    }
   ],
   "source": [
    "test_data = dataset[split_idx[\"test\"]]\n",
    "print(\"Test split sample size: \", len(test_data))\n",
    "test_loader = DataLoader(test_data, batch_size=run_dict[\"batch_size\"], drop_last=False,\n",
    "                         shuffle=False, num_workers=0, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model consists of 110909 trainable parameters.\n",
      "PHC-dim: 4\n",
      "Message passing layers: [200, 200].\n",
      "Downstream layers: [128, 32].\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"hiv/experiment1/run_1/model.pt\").to(DEVICE)\n",
    "if \"sc_type\" not in run_dict.keys():\n",
    "    model.sc_type = \"first\" # include attribute, as this model was trained with a different implementation\n",
    "else:\n",
    "    model.sc_type = run_dict[\"sc_type\"]\n",
    "model = model.eval()\n",
    "print_model_infos(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics_hiv = test_validate_hiv(model, DEVICE, transform, test_loader, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.11866279581909034, 'rocauc': 0.7960370034183742}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics_hiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ogbg-molpcba`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dname=\"ogbg-molpcba\"\n",
    "dataset = PygGraphPropPredDataset(name=dname, root=\"dataset\", transform=None)\n",
    "evaluator = Evaluator(name=dname)\n",
    "split_idx = dataset.get_idx_split()\n",
    "transform = RemoveIsolatedNodes()  # will be applied in the test_validate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pcba/experiment1/params.json\", \"r\") as f:\n",
    "    run_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test split sample size:  43793\n"
     ]
    }
   ],
   "source": [
    "test_data = dataset[split_idx[\"test\"]]\n",
    "print(\"Test split sample size: \", len(test_data))\n",
    "test_loader = DataLoader(test_data, batch_size=run_dict[\"batch_size\"], drop_last=False,\n",
    "                         shuffle=False, num_workers=0, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model consists of 1690328 trainable parameters.\n",
      "PHC-dim: 2\n",
      "Message passing layers: [512, 512, 512, 512, 512, 512, 512].\n",
      "Downstream layers: [768, 256].\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"pcba/experiment1/run_1/model.pt\").to(DEVICE)\n",
    "if \"sc_type\" not in run_dict.keys():\n",
    "    model.sc_type = \"first\" # include attribute, as this model was trained with a different implementation\n",
    "else:\n",
    "    model.sc_type = run_dict[\"sc_type\"]\n",
    "model = model.eval()\n",
    "model = model.eval()\n",
    "print_model_infos(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics_pcba = test_validate_pcba(model, DEVICE, transform, test_loader, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.04663223533899669, 'ap': 0.29484338917596925}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics_pcba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ZINC`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"zinc/experiment1/params.json\", \"r\") as f:\n",
    "    run_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dataset/ZINC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test split sample size:  1000\n"
     ]
    }
   ],
   "source": [
    "test_data = ZINC(path, subset=True, split='test')\n",
    "evaluator = zinc_Evaluator()\n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size=run_dict[\"batch_size\"], drop_last=False,\n",
    "                         shuffle=False, num_workers=0)\n",
    "print(\"Test split sample size: \", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model consists of 106291 trainable parameters.\n",
      "PHC-dim: 5\n",
      "Message passing layers: [200, 200, 200, 200].\n",
      "Downstream layers: [180, 80].\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"zinc/experiment1/run_1/model.pt\").to(DEVICE)\n",
    "if \"sc_type\" not in run_dict.keys():\n",
    "    model.sc_type = \"first\" # include attribute, as this model was trained with a different implementation\n",
    "else:\n",
    "    model.sc_type = run_dict[\"sc_type\"]\n",
    "model = model.eval()\n",
    "model = model.eval()\n",
    "print_model_infos(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics_zinc = test_validate_zinc(model, DEVICE, transform, test_loader, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.18928215515613556, 'mae': 0.1892821490764618}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics_zinc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
